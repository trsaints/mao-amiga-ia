{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa03ed69",
   "metadata": {},
   "source": [
    "# Processamento da Fonte de Dados\n",
    "\n",
    "Este notebook realiza o processo de ETL (extract, transform, load) para as fontes de dados disponibilizadas pelo [Mapa das Organizações da Sociedade Civil](https://mapaosc.ipea.gov.br/base-dados).\n",
    "\n",
    "## Configurando o Ambiente\n",
    "\n",
    "Para manutenção da simplicidade, os códigos necessários para realizar o processamento dos dados estão segmentados em módulos. Este caderno tem o propósito apenas de orquestrar e exibir os resultados dos processamentos realizados por tais módulos.\n",
    "\n",
    "Para isto, é necessário reconfigurar o ambiente do notebook, para que os caminhos dos módulos sejam resolvidos corretamente, como em uma aplicação convencional Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efff15bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"Added to Python path: {project_root}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ac392",
   "metadata": {},
   "source": [
    "## Etapas do Processamento\n",
    "\n",
    "Este caderno executa as seguintes etapas para produzir uma base de dados tratada:\n",
    "\n",
    "### 1. Conversão de Encoding\n",
    "\n",
    "Os datasets disponibilizados encontram-se em diversos formatos, além de contarem com \"encodings\" inadequados para a leitura e análise adequada através de algoritmos.\n",
    "\n",
    "Para cada dataset original, esta etapa gera fontes contendo encoding adequado (em utf8) para a realização de etapas posteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from data.processing.data_parser import to_utf8\n",
    "\n",
    "ONGS_DATASET = input(\n",
    "    \"Enter the ONGS dataset filename (with extension): \").strip()\n",
    "\n",
    "result_path = to_utf8(ONGS_DATASET)\n",
    "\n",
    "if result_path is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"File {ONGS_DATASET} not found or could not be converted to UTF-8.\")\n",
    "\n",
    "reencoded_dataset = pandas.read_csv(result_path, sep=\";\", encoding=\"utf-8\")\n",
    "reencoded_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faf941a",
   "metadata": {},
   "source": [
    "### 2. Tratamento de Organizações\n",
    "\n",
    "A segunda fase lida com as informações disponibilizadas na base `osc_2025_2.csv`, que contém informações sobre as OSCs catalogadas na fonte mencionada.\n",
    "\n",
    "#### 2.1. Tratamento de Áreas de Atuação\n",
    "\n",
    "O dataset original armazena os códigos de área de atuação de cada OSC de maneira tabular, conforme o exemplo abaixo:\n",
    "\n",
    "| Cnpj           | ... | Area_x | Area_y | Area_z |\n",
    "| -------------- | --- | ------ | ------ | ------ |\n",
    "| 00000000000000 | ... | 0      | 1      | 0      |\n",
    "| 11111111111111 | ... | 1      | 0      | 1      |\n",
    "\n",
    "Onde valores `1` indicam que a OSC faz parte da área de atuação correspondente à coluna.\n",
    "\n",
    "Para melhorar a legibilidade do dataset final, esta estrutura é trauzida e concatenada em um único texto descritivo, conforme o exemplo abaixo:\n",
    "\n",
    "| Cnpj           | ... | Areas de Atuação |\n",
    "| -------------- | --- | ---------------- |\n",
    "| 00000000000000 | ... | Area y           |\n",
    "| 11111111111111 | ... | Area x, Area z   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f41e9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.processing.data_parser import osc_dataset\n",
    "\n",
    "osc_df = osc_dataset(reencoded_dataset)\n",
    "osc_df.loc[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
